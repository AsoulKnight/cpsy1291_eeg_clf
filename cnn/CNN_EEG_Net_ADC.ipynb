{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook working directory set to: /oscar/home/lakaiden/cpsy1291_eeg_clf/data/AlzheimerEEG_data/Alzheimer-s-Classification-EEG/data\n",
      "Files in directory: ['ADvsHCFourier.csv', 'CASEVsHCFourier.csv', 'MCIvsADFourier.csv', 'MCIvsHCFourier.csv', 'emp']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "target_path = \"/users/lakaiden/cpsy1291_eeg_clf/data/AlzheimerEEG_data/Alzheimer-s-Classification-EEG/data\"\n",
    "os.chdir(target_path)\n",
    "print(\"Notebook working directory set to:\", os.getcwd())\n",
    "print(\"Files in directory:\", os.listdir(\".\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 0 NaNs\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"ADvsHCFourier.csv\")\n",
    "#dataset is explicity FFT magnitude \n",
    "\n",
    "df['class'] = df['class'].astype(str).str.strip().str.upper() #make sure class labels are normalizes\n",
    "\n",
    "\n",
    "df['label'] = df['class'].map({'AD': 1, 'CONTROL': 0})#mapping AD to 1 ands CONTROL to 0\n",
    "\n",
    "print(\"Before filtering:\", df['label'].isna().sum(), \"NaNs\")\n",
    "\n",
    "# Remove MCI rows(two classses)\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "y = df['label'].astype(int).values\n",
    "\n",
    "# Odrop experiment class and label columns\n",
    "X = df.drop(columns=['experiment', 'class', 'label']).values\n",
    "\n",
    "# Reshape for EEGNet, 19 electrodes, chunk+size of 16\n",
    "X = X.reshape(len(X), 1, 19, 16)\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.temporal = nn.Conv2d(1, 16, kernel_size=(1,5), padding=(0,2), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.depthwise = nn.Conv2d(16, 32, kernel_size=(19,1), groups=16, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.AvgPool2d((1,4))\n",
    "        self.drop1 = nn.Dropout(0.6)\n",
    "        self.separable = nn.Conv2d(32, 32, kernel_size=(1,15), padding=(0,7), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.AvgPool2d((1,2))\n",
    "        self.drop2 = nn.Dropout(0.6)\n",
    "        self.fc = nn.Linear(32 * 1 * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.temporal(x)))\n",
    "        x = torch.relu(self.bn2(self.depthwise(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = torch.relu(self.bn3(self.separable(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return torch.sigmoid(self.fc(x))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "\n",
      "Mean Accuracy: 0.722 ± 0.086\n",
      "Mean ROC-AUC: nan ± nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/lakaiden/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/users/lakaiden/anaconda3/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/users/lakaiden/anaconda3/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/users/lakaiden/anaconda3/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/users/lakaiden/anaconda3/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "accs= [] #list to store performance metrics for each fold  \n",
    "aucs=  [] #\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)): # lloops over each fold in stratified kfold cross validation\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    #splits data based on fold indices\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Flatten data for Standard Scaler\n",
    "    X_train_flat = X_train.reshape(len(X_train), -1)\n",
    "    X_test_flat = X_test.reshape(len(X_test), -1)\n",
    "    #Fit standard scaler\n",
    "    X_train_flat = scaler.fit_transform(X_train_flat)\n",
    "    X_test_flat = scaler.transform(X_test_flat)\n",
    "\n",
    "    #EEGNET input shape transformatoin\n",
    "    X_train = X_train_flat.reshape(len(X_train), 1, 19, 16)\n",
    "    X_test = X_test_flat.reshape(len(X_test), 1, 19, 16)\n",
    "\n",
    "    train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                               torch.tensor(y_train, dtype=torch.float32))\n",
    "    test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                              torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=16)\n",
    "\n",
    "    #initialize EEGNET\n",
    "    model = EEGNet().to(device)\n",
    "    criterion = nn.BCELoss() #Cross entorpy loss of rbinary classification \n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    # Training th emodel \n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model \n",
    "    model.eval()\n",
    "    preds, true = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device)\n",
    "            p = model(xb).cpu().numpy()\n",
    "            preds.extend(p.flatten())\n",
    "            true.extend(yb.numpy())\n",
    "\n",
    "    preds_bin = (np.array(preds) > 0.5).astype(int)#probabiblities ot class predictions\n",
    "    acc = accuracy_score(true, preds_bin)\n",
    "    accs.append(acc)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "print(f\"\\nMean Accuracy: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n",
    "print(f\"Mean ROC-AUC: {np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD         49\n",
      "CONTROL    23\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['class'].value_counts(dropna=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
